import fs from 'fs/promises'
import path from 'path'
import { fileURLToPath } from 'url'
import { createClient } from '@supabase/supabase-js'
import dotenv from 'dotenv'

dotenv.config()

const __dirname = path.dirname(fileURLToPath(import.meta.url))
const dataDir = path.join(__dirname, '..', 'data')

const supabase = createClient(
    process.env.SUPABASE_URL,
    process.env.SUPABASE_ANON_KEY
)

const tables = [
    'users',
    'admins',
    'establishments',
    'categories',
    'services',
    'appointments',
    'employees'
]

async function migrate() {
    console.log('ðŸš€ Iniciando migraÃ§Ã£o JSON -> Supabase...')

    for (const table of tables) {
        try {
            const filePath = path.join(dataDir, `${table}.json`)
            const data = JSON.parse(await fs.readFile(filePath, 'utf-8'))

            console.log(`ðŸ“¦ Migrando ${data.length} registros para a tabela "${table}"...`)

            // Limpar tabela antes (opcional)
            // await supabase.from(table).delete().neq('id', -1)

            // Inserir em lotes para evitar problemas de limite
            const batchSize = 50
            for (let i = 0; i < data.length; i += batchSize) {
                const batch = data.slice(i, i + batchSize)
                const { error } = await supabase.from(table).upsert(batch)

                if (error) {
                    console.error(`âŒ Erro em ${table} (lote ${i}):`, error.message)
                }
            }

            console.log(`âœ… Tabela "${table}" migrada com sucesso!`)
        } catch (error) {
            console.error(`âŒ Falha na migraÃ§Ã£o da tabela "${table}":`, error.message)
        }
    }

    console.log('ðŸ MigraÃ§Ã£o concluÃ­da!')
}

migrate()
